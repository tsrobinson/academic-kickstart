<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Expectation Theorems | 10 Fundamental Theorems for Econometrics</title>
  <meta name="description" content="This book walks through the ten most important statistical theorems as highlighted by Jeffrey Wooldridge, presenting intuiitions, proofs, and applications." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Expectation Theorems | 10 Fundamental Theorems for Econometrics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book walks through the ten most important statistical theorems as highlighted by Jeffrey Wooldridge, presenting intuiitions, proofs, and applications." />
  <meta name="github-repo" content="tsrobinson/10EconTheorems" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Expectation Theorems | 10 Fundamental Theorems for Econometrics" />
  
  <meta name="twitter:description" content="This book walks through the ten most important statistical theorems as highlighted by Jeffrey Wooldridge, presenting intuiitions, proofs, and applications." />
  

<meta name="author" content="Thomas S. Robinson  (https://ts-robinson.com)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="exp-ineq.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">10 Fundamental Theorems for Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#version-notes"><i class="fa fa-check"></i>Version notes</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="exp-theorems.html"><a href="exp-theorems.html"><i class="fa fa-check"></i><b>1</b> Expectation Theorems</a><ul>
<li class="chapter" data-level="1.1" data-path="exp-theorems.html"><a href="exp-theorems.html#law-of-iterated-expectations"><i class="fa fa-check"></i><b>1.1</b> Law of Iterated Expectations</a><ul>
<li class="chapter" data-level="1.1.1" data-path="exp-theorems.html"><a href="exp-theorems.html#proof-of-lie"><i class="fa fa-check"></i><b>1.1.1</b> Proof of LIE</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="exp-theorems.html"><a href="exp-theorems.html#law-of-total-variance"><i class="fa fa-check"></i><b>1.2</b> Law of Total Variance</a><ul>
<li class="chapter" data-level="1.2.1" data-path="exp-theorems.html"><a href="exp-theorems.html#proof-of-ltv"><i class="fa fa-check"></i><b>1.2.1</b> Proof of LTV</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="exp-theorems.html"><a href="exp-theorems.html#linearity-of-expectations"><i class="fa fa-check"></i><b>1.3</b> Linearity of Expectations</a><ul>
<li class="chapter" data-level="1.3.1" data-path="exp-theorems.html"><a href="exp-theorems.html#proof-of-loe"><i class="fa fa-check"></i><b>1.3.1</b> Proof of LOE</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="exp-theorems.html"><a href="exp-theorems.html#variance-of-a-sum"><i class="fa fa-check"></i><b>1.4</b> Variance of a Sum</a><ul>
<li class="chapter" data-level="1.4.1" data-path="exp-theorems.html"><a href="exp-theorems.html#proof-of-vos-x-y-are-independent"><i class="fa fa-check"></i><b>1.4.1</b> Proof of VoS: <span class="math inline">\(X, Y\)</span> are independent</a></li>
<li class="chapter" data-level="1.4.2" data-path="exp-theorems.html"><a href="exp-theorems.html#proof-of-vos-x-y-are-dependent"><i class="fa fa-check"></i><b>1.4.2</b> Proof of VoS: <span class="math inline">\(X, Y\)</span> are dependent</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exp-ineq.html"><a href="exp-ineq.html"><i class="fa fa-check"></i><b>2</b> Inequalities involving expectations</a><ul>
<li class="chapter" data-level="2.1" data-path="exp-ineq.html"><a href="exp-ineq.html#jensens-inequality"><i class="fa fa-check"></i><b>2.1</b> Jensen’s Inequality</a><ul>
<li class="chapter" data-level="2.1.1" data-path="exp-ineq.html"><a href="exp-ineq.html#convex-functions"><i class="fa fa-check"></i><b>2.1.1</b> Convex functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="exp-ineq.html"><a href="exp-ineq.html#the-inequality"><i class="fa fa-check"></i><b>2.1.2</b> The Inequality</a></li>
<li class="chapter" data-level="2.1.3" data-path="exp-ineq.html"><a href="exp-ineq.html#proof_ji"><i class="fa fa-check"></i><b>2.1.3</b> Proof</a></li>
<li class="chapter" data-level="2.1.4" data-path="exp-ineq.html"><a href="exp-ineq.html#application"><i class="fa fa-check"></i><b>2.1.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="exp-ineq.html"><a href="exp-ineq.html#chebyshevs-inequality"><i class="fa fa-check"></i><b>2.2</b> Chebyshev’s Inequality</a><ul>
<li class="chapter" data-level="2.2.1" data-path="exp-ineq.html"><a href="exp-ineq.html#proof"><i class="fa fa-check"></i><b>2.2.1</b> Proof</a></li>
<li class="chapter" data-level="2.2.2" data-path="exp-ineq.html"><a href="exp-ineq.html#applications"><i class="fa fa-check"></i><b>2.2.2</b> Applications</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-projection.html"><a href="linear-projection.html"><i class="fa fa-check"></i><b>3</b> Linear Projection</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-projection.html"><a href="linear-projection.html#proj_def"><i class="fa fa-check"></i><b>3.1</b> Projection</a></li>
<li class="chapter" data-level="3.2" data-path="linear-projection.html"><a href="linear-projection.html#proj_prop"><i class="fa fa-check"></i><b>3.2</b> Properties of the projection matrix</a></li>
<li class="chapter" data-level="3.3" data-path="linear-projection.html"><a href="linear-projection.html#lp_lr"><i class="fa fa-check"></i><b>3.3</b> Linear regression</a><ul>
<li class="chapter" data-level="3.3.1" data-path="linear-projection.html"><a href="linear-projection.html#geometric-interpretation"><i class="fa fa-check"></i><b>3.3.1</b> Geometric interpretation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="wlln.html"><a href="wlln.html"><i class="fa fa-check"></i><b>4</b> Weak Law of Large Numbers and Central Limit Theorem</a><ul>
<li class="chapter" data-level="4.1" data-path="wlln.html"><a href="wlln.html#weak-law-of-large-numbers"><i class="fa fa-check"></i><b>4.1</b> Weak Law of Large Numbers</a><ul>
<li class="chapter" data-level="4.1.1" data-path="wlln.html"><a href="wlln.html#theorem-in-plain-english"><i class="fa fa-check"></i><b>4.1.1</b> Theorem in Plain English</a></li>
<li class="chapter" data-level="4.1.2" data-path="wlln.html"><a href="wlln.html#proof_wlln"><i class="fa fa-check"></i><b>4.1.2</b> Proof</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="wlln.html"><a href="wlln.html#clt"><i class="fa fa-check"></i><b>4.2</b> Central Limit Theorem</a><ul>
<li class="chapter" data-level="4.2.1" data-path="wlln.html"><a href="wlln.html#theorem-in-plain-english-1"><i class="fa fa-check"></i><b>4.2.1</b> Theorem in Plain English</a></li>
<li class="chapter" data-level="4.2.2" data-path="wlln.html"><a href="wlln.html#primer-characteristic-functions"><i class="fa fa-check"></i><b>4.2.2</b> Primer: Characteristic Functions</a></li>
<li class="chapter" data-level="4.2.3" data-path="wlln.html"><a href="wlln.html#proof-of-clt"><i class="fa fa-check"></i><b>4.2.3</b> Proof of CLT</a></li>
<li class="chapter" data-level="4.2.4" data-path="wlln.html"><a href="wlln.html#generalising-clt"><i class="fa fa-check"></i><b>4.2.4</b> Generalising CLT</a></li>
<li class="chapter" data-level="4.2.5" data-path="wlln.html"><a href="wlln.html#limitation-of-clt-and-the-importance-of-wlln"><i class="fa fa-check"></i><b>4.2.5</b> Limitation of CLT (and the importance of WLLN)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="slutsky.html"><a href="slutsky.html"><i class="fa fa-check"></i><b>5</b> Slutsky’s Theorem</a><ul>
<li class="chapter" data-level="5.1" data-path="slutsky.html"><a href="slutsky.html#theorem_slutsky"><i class="fa fa-check"></i><b>5.1</b> Theorem in plain English</a></li>
<li class="chapter" data-level="5.2" data-path="slutsky.html"><a href="slutsky.html#coded-demonstration"><i class="fa fa-check"></i><b>5.2</b> Coded demonstration</a></li>
<li class="chapter" data-level="5.3" data-path="slutsky.html"><a href="slutsky.html#proof-of-slutskys-theorem"><i class="fa fa-check"></i><b>5.3</b> Proof of Slutsky’s Theorem</a><ul>
<li class="chapter" data-level="5.3.1" data-path="slutsky.html"><a href="slutsky.html#cmt"><i class="fa fa-check"></i><b>5.3.1</b> CMT</a></li>
<li class="chapter" data-level="5.3.2" data-path="slutsky.html"><a href="slutsky.html#proof-using-cmt"><i class="fa fa-check"></i><b>5.3.2</b> Proof using CMT</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="slutsky.html"><a href="slutsky.html#applications_slutsky"><i class="fa fa-check"></i><b>5.4</b> Applications</a><ul>
<li class="chapter" data-level="5.4.1" data-path="slutsky.html"><a href="slutsky.html#proving-the-consistency-of-sample-variance-and-the-normality-of-the-t-statistic"><i class="fa fa-check"></i><b>5.4.1</b> Proving the consistency of sample variance, and the normality of the t-statistic</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="big-op-and-little-op.html"><a href="big-op-and-little-op.html"><i class="fa fa-check"></i><b>6</b> Big Op and little op</a><ul>
<li class="chapter" data-level="6.1" data-path="big-op-and-little-op.html"><a href="big-op-and-little-op.html#stochastic-order-notation"><i class="fa fa-check"></i><b>6.1</b> Stochastic order notation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="big-op-and-little-op.html"><a href="big-op-and-little-op.html#relationship-of-big-o-and-little-o"><i class="fa fa-check"></i><b>6.1.1</b> Relationship of big-O and little-o</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="big-op-and-little-op.html"><a href="big-op-and-little-op.html#notational-shorthand-and-arithmetic-properties"><i class="fa fa-check"></i><b>6.2</b> Notational shorthand and ``arithmetic" properties</a></li>
<li class="chapter" data-level="6.3" data-path="big-op-and-little-op.html"><a href="big-op-and-little-op.html#why-is-this-usefulfn_cite1"><i class="fa fa-check"></i><b>6.3</b> Why is this useful?</a></li>
<li class="chapter" data-level="6.4" data-path="big-op-and-little-op.html"><a href="big-op-and-little-op.html#estimator_consistency"><i class="fa fa-check"></i><b>6.4</b> Worked Example: Consistency of mean estimators</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dm.html"><a href="dm.html"><i class="fa fa-check"></i><b>7</b> Delta Method</a><ul>
<li class="chapter" data-level="7.1" data-path="dm.html"><a href="dm.html#delta-method-in-plain-english"><i class="fa fa-check"></i><b>7.1</b> Delta Method in Plain English</a></li>
<li class="chapter" data-level="7.2" data-path="dm.html"><a href="dm.html#proof_dm"><i class="fa fa-check"></i><b>7.2</b> Proof</a><ul>
<li class="chapter" data-level="7.2.1" data-path="dm.html"><a href="dm.html#taylors-series-and-theorem"><i class="fa fa-check"></i><b>7.2.1</b> Taylor’s Series and Theorem</a></li>
<li class="chapter" data-level="7.2.2" data-path="dm.html"><a href="dm.html#proof-of-delta-method"><i class="fa fa-check"></i><b>7.2.2</b> Proof of Delta Method</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dm.html"><a href="dm.html#applied-example"><i class="fa fa-check"></i><b>7.3</b> Applied example</a></li>
<li class="chapter" data-level="7.4" data-path="dm.html"><a href="dm.html#alternative-strategies"><i class="fa fa-check"></i><b>7.4</b> Alternative strategies</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="frisch.html"><a href="frisch.html"><i class="fa fa-check"></i><b>8</b> Frisch-Waugh-Lovell Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="wlln.html"><a href="wlln.html#theorem-in-plain-english"><i class="fa fa-check"></i><b>8.1</b> Theorem in plain English</a></li>
<li class="chapter" data-level="8.2" data-path="frisch.html"><a href="frisch.html#proof_fw"><i class="fa fa-check"></i><b>8.2</b> Proof</a><ul>
<li class="chapter" data-level="8.2.1" data-path="frisch.html"><a href="frisch.html#primer-projection-matricessecnote"><i class="fa fa-check"></i><b>8.2.1</b> Primer: Projection matrices</a></li>
<li class="chapter" data-level="8.2.2" data-path="frisch.html"><a href="frisch.html#fwl-proof-secnote2"><i class="fa fa-check"></i><b>8.2.2</b> FWL Proof</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="frisch.html"><a href="frisch.html#coded-example"><i class="fa fa-check"></i><b>8.3</b> Coded example</a></li>
<li class="chapter" data-level="8.4" data-path="frisch.html"><a href="frisch.html#application-sensitivity-analysis"><i class="fa fa-check"></i><b>8.4</b> Application: Sensitivity analysis</a><ul>
<li class="chapter" data-level="8.4.1" data-path="frisch.html"><a href="frisch.html#regressing-the-partialled-out-x-on-the-full-y"><i class="fa fa-check"></i><b>8.4.1</b> Regressing the partialled-out X on the full Y</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="pd.html"><a href="pd.html"><i class="fa fa-check"></i><b>9</b> Positive Definite Matrices</a><ul>
<li class="chapter" data-level="9.1" data-path="pd.html"><a href="pd.html#pd_terms"><i class="fa fa-check"></i><b>9.1</b> Terminology</a><ul>
<li class="chapter" data-level="9.1.1" data-path="pd.html"><a href="pd.html#positivity"><i class="fa fa-check"></i><b>9.1.1</b> Positivity</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="pd.html"><a href="pd.html#a-b-is-psd-iff-b-1---a-1-is-psd"><i class="fa fa-check"></i><b>9.2</b> <span class="math inline">\(A-B\)</span> is PSD iff <span class="math inline">\(B^{-1} - A^{-1}\)</span> is PSD</a><ul>
<li class="chapter" data-level="9.2.1" data-path="pd.html"><a href="pd.html#pd_proof"><i class="fa fa-check"></i><b>9.2.1</b> Proof</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="pd.html"><a href="pd.html#pd_app"><i class="fa fa-check"></i><b>9.3</b> Applications</a><ul>
<li class="chapter" data-level="9.3.1" data-path="pd.html"><a href="pd.html#ols-as-the-best-linear-unbiased-estimator-blue"><i class="fa fa-check"></i><b>9.3.1</b> OLS as the best linear unbiased estimator (BLUE)</a></li>
<li class="chapter" data-level="9.3.2" data-path="pd.html"><a href="pd.html#optimisation-problems"><i class="fa fa-check"></i><b>9.3.2</b> Optimisation problems</a></li>
<li class="chapter" data-level="9.3.3" data-path="pd.html"><a href="pd.html#recap"><i class="fa fa-check"></i><b>9.3.3</b> Recap</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">10 Fundamental Theorems for Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exp_theorems" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Expectation Theorems</h1>
<p>This chapter sets out some of the basic theorems that can be derived from the definition of expectations, as highlighted by Wooldridge. I have combined his first two points into a single overview of expectation maths. The theorems themselves are not as immediately relevant to applied research as some of the later theorems on Wooldridge’s list. However, they often form the fundamental basis upon which future proofs are conducted.</p>
<div id="law-of-iterated-expectations" class="section level2">
<h2><span class="header-section-number">1.1</span> Law of Iterated Expectations</h2>
<p>The Law of Iterated Expectations (LIE) states that:</p>
<p><span class="math display">\[\begin{equation}
    \mathbb{E}[X] = \mathbb{E}[\mathbb{E}[X|Y]]
\end{equation}\]</span></p>
<p>In plain English, the expected value of <span class="math inline">\(X\)</span> is equal to the expectation over the conditional expectation of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y\)</span>. More simply, the mean of X is equal to a weighted mean of conditional means.</p>
<p>Aronow &amp; Miller <span class="citation">(<a href="#ref-aronow2019foundations" role="doc-biblioref">2019</a>)</span> note that LIE is `one of the most important theorems’, because being able to express unconditional expectation functions in terms of conditional expectations allow you to hold some parameters fixed, making calculations more tractable.</p>
<div id="proof-of-lie" class="section level3">
<h3><span class="header-section-number">1.1.1</span> Proof of LIE</h3>
<p>First, we can express the expectation over conditional expectations as a weighted sum over all possible values of Y, and similarly express the conditional expectations using summation too:</p>
<p><span class="math display">\[\begin{align}
    \mathbb{E}[\mathbb{E}[X|Y]] &amp;= \sum_y\mathbb{E}[X|Y=y]P(Y=y) \\
          &amp;= \sum_y\sum_x xP(X=x|Y=y)P(Y=y) \label{eq:lie_expand} \\
          &amp;= \sum_y\sum_x xP(Y=y|X=x)P(X=x). \label{eq:lie_bayes},
\end{align}\]</span></p>
<p>Note that the final line follows due to Bayes’ Rule.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> And so:</p>
<p><span class="math display">\[\begin{align}
    ... &amp;= \sum_y\sum_x xP(X=x)P(Y=y|X=x) \label{eq:rearrange}\\
          &amp;= \sum_x xP(X=x) \sum_y P(Y=y|X=x) \label{eq:shift}\\
          &amp;= \sum_x xP(X=x) \label{eq:equals_one}\\
          &amp;= \mathbb{E}[X] \; \; \; \square
\end{align}\]</span></p>
<p>The last steps of the proof are reasonably simple. Equation  is a trivial rearrangement of terms. The second line follows since <span class="math inline">\(y\)</span> does not appear in <span class="math inline">\(xP(X=x)\)</span> and so we can move the summation over <span class="math inline">\(Y\)</span> to within the summation over <span class="math inline">\(X\)</span>. The final line follows from the fact that the sum of the conditional probabilities <span class="math inline">\(P(Y=y|X=x)=1\)</span> (by simple probability theory).</p>
</div>
</div>
<div id="law-of-total-variance" class="section level2">
<h2><span class="header-section-number">1.2</span> Law of Total Variance</h2>
<p>The Law of Total Variance (LTV) states the following:
<span class="math display">\[\begin{equation}
    var[Y] = \mathbb{E}[var[Y|X]] + var(\mathbb{E}[Y|X])
\end{equation}\]</span></p>
<div id="proof-of-ltv" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Proof of LTV</h3>
<p>LTV can be proved almost immediately using LIE and the definition of variance:</p>
<p><span class="math display">\[\begin{align}
    var(Y) &amp;= \mathbb{E}[Y^2] - \mathbb{E}[Y]^2 \label{eq:var_def} \\ 
           &amp;= \mathbb{E}[\mathbb{E}[Y^2|X]] - \mathbb{E}[\mathbb{E}[Y|X]]^2 \label{eq:var_lie} \\ 
           &amp;= \mathbb{E}[var[Y|X] + \mathbb{E}[Y]^2]] - \mathbb{E}[\mathbb{E}[Y|X]]^2 \label{eq:var_by10}\\
           &amp;= \mathbb{E}[var[Y|X]] + (\mathbb{E}[\mathbb{E}[Y]^2] - \mathbb{E}[\mathbb{E}[Y|X]]^2) \label{eq:var_eshift}\\
           &amp;= \mathbb{E}[var[Y|X]] + var(\mathbb{E}[Y|X]) \label{eq:var_by10_2} \; \; \; \square
\end{align}\]</span></p>
<p>The second line applies LIE to both <span class="math inline">\(Y^2\)</span> and <span class="math inline">\(Y\)</span> separately. Then we apply the definition of variance to <span class="math inline">\(\mathbb{E}[Y^2|X]\)</span>, and subsequently decompose this term (since <span class="math inline">\(\mathbb{E}[A+B] = \mathbb{E}[A] + \mathbb{E}[B]\)</span>.</p>
</div>
</div>
<div id="linearity-of-expectations" class="section level2">
<h2><span class="header-section-number">1.3</span> Linearity of Expectations</h2>
<p>The Linearity of Expectations (LOE) simply states that:</p>
<p><span class="math display">\[\begin{equation}
    \mathbb{E}[aX + bY] = a\mathbb{E}[X] + b\mathbb{E}[Y],
\end{equation}\]</span></p>
<p>where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are real numbers, and <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are random variables.</p>
<div id="proof-of-loe" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Proof of LOE</h3>
<p><span class="math display">\[\begin{align}
    \mathbb{E}[aX + bY] &amp;= \sum_x\sum_y (ax+by) P(X=x, Y=y) \label{eq:loe_sums} \\
    &amp;= \sum_x\sum_y ax P(X=x, Y=y) + \sum_x\sum_y by P(X=x, Y=y) \\
    &amp;= a\sum_x x\sum_y P(X=x, Y=y) + b \sum_y y \sum_x P(X=x, Y=y) \label{eq:loe_rearrange}\\ 
\end{align}\]</span></p>
<p>The first line simply expands the expectation into summation form i.e. the expectation is the sum of <span class="math inline">\(aX + bY\)</span> for each (discrete) value of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> weighted by their joint probability. We then expand out these terms. Since summations are commutative, we can rearrange the order of the summations for each of the two parts in the final line, and shift the real numbers and random variables outside the various operators.</p>
<p>Now note that <span class="math inline">\(\sum_{i} P(I=i, J=j) \equiv P(J=j)\)</span> by probability theory. Therefore:</p>
<p><span class="math display">\[\begin{align}
    ... &amp;= a\sum_x x P(X=x) + b\sum_y y P(Y = y)
\end{align}\]</span></p>
<p>The two terms within summations are just the weighted averages of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> respectively, i.e. the expectations of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, so:</p>
<p><span class="math display">\[\begin{align}
    ... &amp;= a\mathbb{E}[X] + b\mathbb{E}[Y] \; \; \; \square \\
\end{align}\]</span></p>
</div>
</div>
<div id="variance-of-a-sum" class="section level2">
<h2><span class="header-section-number">1.4</span> Variance of a Sum</h2>
<p>There are two versions of the Variance of a Sum (VOS) law:</p>
<ul>
<li><span class="math inline">\(var(X + Y) = var(X) + var(Y),\)</span> when X and Y are independent</li>
<li><span class="math inline">\(var(X+Y) = var(X) + var(Y) + 2Cov(X,Y)\)</span>, when X and Y are correlated</li>
</ul>
<div id="proof-of-vos-x-y-are-independent" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Proof of VoS: <span class="math inline">\(X, Y\)</span> are independent</h3>
<p><span class="math display">\[\begin{align}
    var(X + Y) &amp;= \mathbb{E}[(X+Y)^2] - (\mathbb{E}[X+Y])^2 \\
    &amp;= \mathbb{E}[(X^2 + 2XY + Y^2)] - (\mathbb{E}[X] + \mathbb{E}[Y])^2
\end{align}\]</span></p>
<p>The first line of the proof is simply the definition of variance. In the second line, we expand the equation in the first term and using LOE decompose the second term. We can expand this equation further, continuing to use LOE and noting that :</p>
<p><span class="math display">\[\begin{align}
    ... &amp;= \mathbb{E}[X^2] + \mathbb{E}[2XY] + \mathbb{E}[Y^2] - (\mathbb{E}[X]^2 + 2\mathbb{E}[X]\mathbb{E}[Y] + \mathbb{E}[Y]^2)\\
     &amp;= \mathbb{E}[X^2] + \mathbb{E}[Y^2] - \mathbb{E}[X]^2 - \mathbb{E}[Y]^2 \\
     &amp;= Var[X] + Var[Y] \; \; \; \square
\end{align}\]</span></p>
<p>since <span class="math inline">\(\mathbb{E}[A]\mathbb{E}[B] = \mathbb{E}[AB]\)</span> when <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent.</p>
</div>
<div id="proof-of-vos-x-y-are-dependent" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Proof of VoS: <span class="math inline">\(X, Y\)</span> are dependent</h3>
<p>As before, we can expand out the variance of a sum into its expected values:</p>
<p><span class="math display">\[\begin{align}
    var(X + Y) &amp;= \mathbb{E}[X^2] + \mathbb{E}[2XY] + \mathbb{E}[Y^2] - (\mathbb{E}[X]^2 + 2\mathbb{E}[X]\mathbb{E}[Y] + \mathbb{E}[Y]^2).
\end{align}\]</span></p>
<p>Since <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are assumed to be dependent, the non-squared terms do not necessarily cancel each other out anymore. Instead, we can rearrange as follows:</p>
<p><span class="math display">\[\begin{align}
    var(X + Y) &amp;= var(X) + var(Y) + \mathbb{E}[2XY] - 2\mathbb{E}[X]\mathbb{E}[Y]\\
    &amp; = var(X) + var(Y) + 2(\mathbb{E}[XY] - \mathbb{E}[X]\mathbb{E}[Y]),
\end{align}\]</span></p>
<p>and note that <span class="math inline">\(\mathbb{E}[AB]-\mathbb{E}[A]\mathbb{E}[B] = Cov(A,B)\)</span>:</p>
<p><span class="math display">\[\begin{equation}
... = var(X) + var(Y) + 2Cov(A,B) \; \; \; \square
\end{equation}\]</span></p>
<p>Two further points are worth noting. First, the independent version of the proof is just a special case of the dependent version of the proof. When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, the covariance between the two random variables is zero, and therefore the the variance of the sum is just equal to the sum of the variances.</p>
<p>Second, nothing in the above proofs rely on there being just two random variables. In fact, <span class="math inline">\(var(\sum^n_i X_i) = \sum^n_ivar(X_i)\)</span> when all variables are independent from each other, and equal to <span class="math inline">\(\sum^n_ivar(X_i) + 2\sum^n_{1 \leq i &lt; j \leq n}Cov(X_i,X_j).\)</span> This can be proved by induction using the above proofs, but intuitively: we can replace, for example, <span class="math inline">\(Y\)</span> with <span class="math inline">\(Y = (Y_1 + Y_2)\)</span> and iteratively apply the above proof first to <span class="math inline">\(X+Y\)</span> and then subsequently expand <span class="math inline">\(var(Y)\)</span> as <span class="math inline">\(var(Y_1+Y_2)\)</span>.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-aronow2019foundations">
<p>Aronow, P. M., and B. T. Miller. 2019. <em>Foundations of Agnostic Statistics</em>. Cambridge University Press. <a href="https://books.google.co.uk/books?id=u1N-DwAAQBAJ">https://books.google.co.uk/books?id=u1N-DwAAQBAJ</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Bayes’ Rule states <span class="math inline">\(P(A|B) = \frac{P(B|A)P(A)}{P(B)}\)</span>. Therefore:
<span class="math display">\[\begin{equation*}
P(X=x|Y=y)\times P(Y=y) = \frac{P(Y=y|X=x)P(X=x) P(Y=y)}{P(Y=y)} = P(Y=y|X=x)P(X=x).
\end{equation*}\]</span><a href="exp-theorems.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exp-ineq.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-expectation-functions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["10EconometricTheorems.pdf", "10EconometricTheorems.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
